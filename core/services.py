import logging
import requests
from django.conf import settings
from datetime import datetime, timedelta
from .gemini_service import generate_search_queries, analyze_vacancies_batch

logger = logging.getLogger('core')


def get_hh_vacancies(student_profile=None, per_page=10, max_queries=1, batch_count=1):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–∑ HeadHunter API
    
    Args:
        student_profile: –ø—Ä–æ—Ñ–∏–ª—å —Å—Ç—É–¥–µ–Ω—Ç–∞ (–µ—Å–ª–∏ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω)
        per_page: —Å–∫–æ–ª—å–∫–æ –≤–∞–∫–∞–Ω—Å–∏–π –≤–µ—Ä–Ω—É—Ç—å
        max_queries: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1)
    """
    logger.info("=" * 80)
    logger.info("üåê –ó–ê–ü–†–û–° –í–ê–ö–ê–ù–°–ò–ô –ò–ó HeadHunter API")
    logger.info("=" * 80)
    
    list_url = settings.HH_API_URL
    headers = {'User-Agent': 'CareerAI/1.0'}

    all_vacancies = []
    unique_ids = set()
    
    # ==================== –ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–û–ò–°–ö–û–í–´–• –ó–ê–ü–†–û–°–û–í ====================
    if student_profile:
        logger.info(f"‚úÖ –°—Ç—É–¥–µ–Ω—Ç –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω (ID: {student_profile.person_id})")
        logger.info(f"   –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å: {student_profile.education.specialization if hasattr(student_profile, 'education') else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–º–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã —á–µ—Ä–µ–∑ Gemini
        search_queries = generate_search_queries(student_profile, max_queries=max_queries)
        
        logger.info("-" * 80)
        logger.info(f"üîç –ë—É–¥–µ–º –∏—Å–∫–∞—Ç—å –ø–æ {len(search_queries)} {'–∑–∞–ø—Ä–æ—Å—É' if len(search_queries) == 1 else '–∑–∞–ø—Ä–æ—Å–∞–º'}:")
        for i, query in enumerate(search_queries, 1):
            logger.info(f"   {i}. '{query}'")
        
    else:
        logger.info("‚ÑπÔ∏è  –ì–æ—Å—Ç—å (–Ω–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω)")
        search_queries = [None]  # –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞
    
    # ==================== –ü–û–ò–°–ö –ü–û –í–°–ï–ú –ó–ê–ü–†–û–°–ê–ú ====================
    queries_used = 0
    min_vacancies_needed = 10  # –ú–∏–Ω–∏–º—É–º –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
    
    for idx, query in enumerate(search_queries, 1):
        logger.info("-" * 80)
        if query:
            logger.info(f"üì° –ó–∞–ø—Ä–æ—Å #{idx}/{len(search_queries)}: '{query}'")
        else:
            logger.info(f"üì° –ó–∞–ø—Ä–æ—Å #{idx}/{len(search_queries)}: –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞")
        
        params = {
            'area': '40',
            'per_page': 50,
            'page': 0,
            'order_by': 'publication_time'
        }
        
        if query:
            params['text'] = query
            params['experience'] = 'noExperience'
        
        try:
            response = requests.get(list_url, params=params, headers=headers, timeout=10)
            response.raise_for_status()
            items = response.json().get('items', [])
            
            logger.info(f"   ‚úÖ –ü–æ–ª—É—á–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(items)}")
            
            new_count = 0
            for item in items:
                vacancy_id = item.get('id')
                if vacancy_id and vacancy_id not in unique_ids:
                    unique_ids.add(vacancy_id)
                    all_vacancies.append(item)
                    new_count += 1
            
            logger.info(f"   ‚úì –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {new_count}")
            logger.info(f"   üìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {len(all_vacancies)}")
            
            queries_used += 1
            
            # ========== –ü–†–û–í–ï–†–ö–ê: –ù–£–ñ–ï–ù –õ–ò –ï–©–ï –ó–ê–ü–†–û–°? ==========
            if len(all_vacancies) < min_vacancies_needed and queries_used < len(search_queries):
                logger.warning(f"   ‚ö†Ô∏è  –í—Å–µ–≥–æ {len(all_vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π (–º–∏–Ω: {min_vacancies_needed})")
                logger.info(f"   ‚û°Ô∏è  –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–µ–ª–∞–µ–º –µ—â–µ –æ–¥–∏–Ω –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å...")
                continue  # –ò–¥–µ–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –∑–∞–ø—Ä–æ—Å—É
            else:
                logger.info(f"   ‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–∏—Å–∫")
                break  # –•–≤–∞—Ç–∏—Ç, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
            
        except requests.RequestException as e:
            logger.error(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            queries_used += 1
            continue
    
    # ==================== –ó–ê–ì–†–£–ó–ö–ê –î–ï–¢–ê–õ–ï–ô ====================
    logger.info("-" * 80)
    logger.info(f"üîç –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–µ—Ç–∞–ª–∏ –¥–ª—è {len(all_vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π...")
    
    vacancies = []
    for idx, item in enumerate(all_vacancies, 1):
        detail_url = item.get('url')
        if not detail_url:
            continue
        
        try:
            detail_response = requests.get(detail_url, headers=headers, timeout=5)
            detail_response.raise_for_status()
            item_details = detail_response.json()
            
            key_skills_list = [skill['name'] for skill in item_details.get('key_skills', [])]
            
            if idx <= 5:
                logger.info(f"  ‚úì –í–∞–∫–∞–Ω—Å–∏—è #{idx}: {item.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                logger.info(f"      –ù–∞–≤—ã–∫–∏: {', '.join(key_skills_list[:3]) if key_skills_list else '–Ω–µ —É–∫–∞–∑–∞–Ω—ã'}")
        
        except requests.RequestException:
            key_skills_list = []
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∑–∞—Ä–ø–ª–∞—Ç—É
        salary = item.get('salary')
        salary_display = "–ù–µ —É–∫–∞–∑–∞–Ω–∞"
        if salary:
            salary_from = salary.get('from')
            salary_to = salary.get('to')
            currency = salary.get('currency', '').upper()
            
            if salary_from and salary_to:
                salary_display = f"{salary_from:,} - {salary_to:,} {currency}".replace(',', ' ')
            elif salary_from:
                salary_display = f"–æ—Ç {salary_from:,} {currency}".replace(',', ' ')
            elif salary_to:
                salary_display = f"–¥–æ {salary_to:,} {currency}".replace(',', ' ')
        
        vacancies.append({
            'id': item.get('id'),
            'title': item.get('name'),
            'company': item.get('employer', {}).get('name'),
            'city': item.get('area', {}).get('name'),
            'salary': salary_display,
            'url': item.get('alternate_url'),
            'employment': item.get('employment', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
            'snippet': item.get('snippet', {}).get('requirement') or "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è.",
            'skills': key_skills_list,
        })
    
    if len(all_vacancies) > 5:
        logger.info(f"  ... –∏ –µ—â–µ {len(all_vacancies) - 5} –≤–∞–∫–∞–Ω—Å–∏–π")
    
    logger.info(f"‚úÖ –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(vacancies)}")
    
    # ==================== GEMINI –ê–ù–ê–õ–ò–ó ====================
    logger.info("-" * 80)
    if student_profile and vacancies:
        logger.info(f"ü§ñ –°—Ç—É–¥–µ–Ω—Ç –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω ‚Üí –∑–∞–ø—É—Å–∫–∞–µ–º Gemini-–∞–Ω–∞–ª–∏–∑...")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ Gemini
        analyzed = analyze_vacancies_batch(vacancies, student_profile, batch_size=20, max_batches=batch_count)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-N (—É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤–Ω—É—Ç—Ä–∏ analyze_vacancies_batch)
        logger.info(f"‚úÖ –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-{per_page} –≤–∞–∫–∞–Ω—Å–∏–π —Å Gemini-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏")
        logger.info("=" * 80)
        return analyzed[:per_page]
    else:
        logger.info(f"‚ÑπÔ∏è  –ì–æ—Å—Ç—å ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ {per_page} –≤–∞–∫–∞–Ω—Å–∏–π –ë–ï–ó Gemini-–∞–Ω–∞–ª–∏–∑–∞")
        logger.info("=" * 80)
        return vacancies[:per_page]